{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e757cf0-e531-49b9-8346-21ab5cea7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d71c0b-6bc1-4be4-96d3-a39f57974167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Initialize the chatbot with a specific model and temperature\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0.5,  # A higher temperature for more empathetic responses\n",
    "    groq_api_key='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'\n",
    ")\n",
    "\n",
    "# Predefined responses for greetings and bot-related queries\n",
    "greeting_responses = {\n",
    "    \"hello\": \"Hello! How can I help you today?\",\n",
    "    \"hi\": \"Hi there! What would you like to talk about?\",\n",
    "    \"hey\": \"Hey! I'm here to support you.\",\n",
    "    \"good morning\": \"Good morning! How are you feeling today?\",\n",
    "    \"good afternoon\": \"Good afternoon! How can I assist you?\",\n",
    "    \"good evening\": \"Good evening! How's your day been?\",\n",
    "}\n",
    "\n",
    "bot_related_responses = {\n",
    "    \"who are you\": \"I’m a mental health support chatbot. I'm here to provide empathetic responses and assist with questions related to the mind and emotions.\",\n",
    "    \"what can you do\": \"I can help answer questions about mental health, thoughts, feelings, and other mind-related topics. Feel free to ask anything!\",\n",
    "    \"tell me about yourself\": \"I’m designed to offer emotional support and help with mind-related topics, but I’m not a substitute for professional help. How can I assist you today?\"\n",
    "}\n",
    "\n",
    "def is_mind_related_question(prompt):\n",
    "    \"\"\"\n",
    "    Checks if the user's prompt is related to the mind, including various mental processes\n",
    "    like thinking, visualizing, imagining, and others.\n",
    "    \"\"\"\n",
    "    mind_related_keywords = [\n",
    "        \"mind\", \"brain\", \"thoughts\", \"thinking\", \"feelings\", \"emotions\", \"mental health\", \n",
    "        \"anxiety\", \"depression\", \"stress\", \"therapy\", \"counseling\", \"self-care\", \n",
    "        \"motivation\", \"focus\", \"concentration\", \"memory\", \"learning\", \"intelligence\",\n",
    "        \"daydreaming\", \"mood\", \"meditation\", \"mindfulness\", \"behavior\", \"imagine\",\n",
    "        \"visualize\", \"visualizing\", \"recall\", \"dream\", \"dreaming\", \"fantasize\", \"fantasy\",\n",
    "        \"ruminate\", \"overthink\", \"self-talk\", \"inner dialogue\", \"mental imagery\", \n",
    "        \"cognition\", \"cognitive\", \"plan\", \"planning\", \"creative thinking\", \"subconscious\"\n",
    "    ]\n",
    "    \n",
    "    action_keywords = [\n",
    "        \"stop\", \"avoid\", \"control\", \"manage\", \"handle\", \"clear\", \"focus on\", \"concentrate on\", \n",
    "        \"remove\", \"stop thinking\", \"deal with\", \"visualize\", \"imagine\", \"plan\", \"process\"\n",
    "    ]\n",
    "\n",
    "    # Convert the prompt to lowercase for easier comparison\n",
    "    prompt_lower = prompt.lower()\n",
    "\n",
    "    # Check for mind-related keywords directly\n",
    "    for keyword in mind_related_keywords:\n",
    "        if keyword in prompt_lower:\n",
    "            return True\n",
    "\n",
    "    # Allow prompts involving mental actions combined with activities\n",
    "    for action in action_keywords:\n",
    "        if action in prompt_lower and (\"thinking\" in prompt_lower or \"mind\" in prompt_lower or \"imagine\" in prompt_lower):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def handle_greetings_or_bot_questions(prompt):\n",
    "    \"\"\"\n",
    "    Handles simple greetings and general queries about the bot.\n",
    "    \"\"\"\n",
    "    prompt_lower = prompt.lower()\n",
    "    \n",
    "    # Check for greetings\n",
    "    for greeting in greeting_responses:\n",
    "        if greeting in prompt_lower:\n",
    "            return greeting_responses[greeting]\n",
    "    \n",
    "    # Check for bot-related queries\n",
    "    for query in bot_related_responses:\n",
    "        if query in prompt_lower:\n",
    "            return bot_related_responses[query]\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Chat function with conversation history handling\n",
    "def chatbot_response(user_prompt, chat_history):\n",
    "    \"\"\"\n",
    "    Handles the user's input and appends to the conversation history.\n",
    "    The chatbot generates responses based on the entire conversation history.\n",
    "    \"\"\"\n",
    "    # Check if it's a greeting or a bot-related question\n",
    "    predefined_response = handle_greetings_or_bot_questions(user_prompt)\n",
    "    \n",
    "    if predefined_response:\n",
    "        chat_history.append((\"Bot\", predefined_response))\n",
    "        return chat_history\n",
    "\n",
    "    # Append the user's query to the chat history\n",
    "    chat_history.append((\"User\", user_prompt))\n",
    "    \n",
    "    # Check if the user's prompt is related to the mind\n",
    "    if not is_mind_related_question(user_prompt):\n",
    "        chat_history.append((\"Bot\", \"Please ask only about questions related to the mind (e.g., thoughts, feelings, emotions, imagination).\"))\n",
    "        return chat_history\n",
    "    \n",
    "    # Prepare the conversation as a string, appending each previous turn\n",
    "    conversation = \"\\n\".join([f\"{speaker}: {message}\" for speaker, message in chat_history])\n",
    "\n",
    "    # Prepend a guiding prompt to help the model respond empathetically\n",
    "    mind_related_prompt = f\"I’m here to listen and offer support. Respond with empathy and understanding. Here is the conversation so far:\\n{conversation}\\n{user_prompt}\"\n",
    "\n",
    "    try:\n",
    "        # Get the model's response\n",
    "        res = llm.invoke(mind_related_prompt)\n",
    "        # Append the model's response to the chat history\n",
    "        chat_history.append((\"Bot\", res.content))\n",
    "    except Exception as e:\n",
    "        chat_history.append((\"Bot\", \"Sorry, there was an issue processing your request. Please try again.\"))\n",
    "    \n",
    "    return chat_history\n",
    "\n",
    "# Gradio interface\n",
    "def launch_gradio_interface():\n",
    "    # Create a Gradio interface with a chat-like textbox and output\n",
    "    with gr.Blocks() as demo:\n",
    "        # Create a state to hold the chat history\n",
    "        chat_history = gr.State([])\n",
    "\n",
    "        # Chat interface: input textbox and output box\n",
    "        with gr.Row():\n",
    "            user_input = gr.Textbox(label=\"Ask your mind-related question\")\n",
    "            chat_output = gr.Chatbot(label=\"Mental Health Support Chatbot\")\n",
    "\n",
    "        # Button to submit the user query\n",
    "        submit_button = gr.Button(\"Submit\")\n",
    "\n",
    "        # Function to update the chat history with each new input\n",
    "        def update_chat(user_prompt, chat_history):\n",
    "            chat_history = chatbot_response(user_prompt, chat_history)\n",
    "            return chat_history, chat_history, \"\"\n",
    "\n",
    "        # Button to clear only the user prompt\n",
    "        def clear_prompt():\n",
    "            return \"\"\n",
    "\n",
    "        # Button to clear both the user prompt and the chat history\n",
    "        def clear_chat():\n",
    "            return [], [], \"\"\n",
    "\n",
    "        # Add a button to clear the user input only\n",
    "        clear_prompt_button = gr.Button(\"Clear Prompt\")\n",
    "\n",
    "        # Add a button to clear both the user input and the chat history\n",
    "        clear_chat_button = gr.Button(\"Clear Chat\")\n",
    "\n",
    "        # Link the user input and chat history updates\n",
    "        submit_button.click(update_chat, inputs=[user_input, chat_history], outputs=[chat_output, chat_history, user_input])\n",
    "\n",
    "        # Link the clear buttons to their respective functions\n",
    "        clear_prompt_button.click(clear_prompt, inputs=[], outputs=[user_input])\n",
    "        clear_chat_button.click(clear_chat, inputs=[], outputs=[chat_output, chat_history, user_input])\n",
    "\n",
    "    # Launch the Gradio UI\n",
    "    demo.launch()\n",
    "\n",
    "# Run the Gradio interface\n",
    "launch_gradio_interface()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4961102c-b7f3-495e-a7c9-8195bb29985f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
